{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**The objective of this step is to the modeling and evaluation phase, specifically focusing on the application of Logistic Regression to predict categorical targets. The evaluation includes comparing the performance of the model before and after outlier handling, as well as comparing the results of dimensionality reduction using Linear Discriminant Analysis (LDA) and Principal Component Analysis (PCA).**\n",
    "\n",
    "**Modeling with Logistic Regression:**\n",
    "Logistic Regression was chosen as the modeling algorithm due to its suitability for predicting categorical targets. It is a widely used algorithm for binary and multiclass classification tasks.\n",
    "\n",
    "**Training and Testing:**\n",
    "The dataset was split into training and testing sets to train the model and assess its performance on unseen data.\n",
    "\n",
    "PCA with outliers:\n",
    "       accuarcy:\n",
    "       target1= 0.92\n",
    "       target1= 0.89\n",
    "\n",
    "LDA with outliers:\n",
    "       accuarcy:\n",
    "       target1 = 0.93\n",
    "       target1 = 0.90\n",
    "\n",
    "PCA without outliers:\n",
    "       accuarcy:\n",
    "       target 1:0.92\n",
    "       target 2: 0.89\n",
    "\n",
    "LDA without outliers:\n",
    "       accuarcy:\n",
    "       target 1:0.93\n",
    "       target 2: 0.90\n",
    "\n",
    "results show that LDA performs better than PCA in diffrent metrics i use it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1- import and reading data (with outlier and without it)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../scripts/utilities')\n",
    "from helper_functions import *\n",
    "\n",
    "sys.path.append('../../scripts/modeling')\n",
    "from modeling import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "base_path = '../../data/processed_data/'\n",
    "df_PCA_with_outlier = read_files('df_filling_missing_values_with_median_encoded_handle_noisy_normalized_highly_correlated_PCA_with_outliers.csv',\n",
    "                 base_path=base_path)[0]\n",
    "df_LDA_with_outlier = read_files('df_filling_missing_values_with_median_encoded_handle_noisy_normalized_highly_correlated_LDA_with_outliers.csv',\n",
    "                 base_path=base_path)[0]\n",
    "\n",
    "df_PCA_without_outlier = read_files('df_filling_missing_values_with_median_encoded_handle_noisy_handle_outlier_normalized_highly_correlated_perform_PCA.csv',\n",
    "                 base_path=base_path)[0]\n",
    "\n",
    "df_LDA_without_outlier = read_files('df_filling_missing_values_with_median_encoded_handle_noisy_handle_outlier_normalized_highly_correlated_perform_LDA.csv',\n",
    "                 base_path=base_path)[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train and evaluate PCA with outlier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2- Split the data into training and testing sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X, y1, y2 = split_dataset(df_PCA_with_outlier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3- Split the data into training and testing sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = split_train_test(X, y1)\n",
    "X_train2, X_test2, y_train2, y_test2 = split_train_test(X, y2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4- Standardize the features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train_scaled1, X_test_scaled1 = standardize_features(X_train1, X_test1)\n",
    "X_train_scaled2, X_test_scaled2 = standardize_features(X_train2, X_test2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5- Create and train the logistic regression model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model_target1 = train_logistic_regression(X_train_scaled1, y_train1)\n",
    "model_target2 = train_logistic_regression(X_train_scaled2, y_train2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6- Make predictions on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "y_pred1 = predict(model_target1, X_test_scaled1)\n",
    "y_pred2 = predict(model_target2, X_test_scaled2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7- evaluate models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "({'accuracy': 0.9253071253071253,\n  'classification_report': '              precision    recall  f1-score   support\\n\\n         0.0       0.96      0.92      0.94       875\\n         1.0       1.00      0.00      0.00        46\\n         2.0       0.90      0.97      0.93      1114\\n\\n    accuracy                           0.93      2035\\n   macro avg       0.95      0.63      0.62      2035\\nweighted avg       0.93      0.93      0.91      2035\\n',\n  'confusion_matrix': array([[ 805,    0,   70],\n         [   0,    0,   46],\n         [  36,    0, 1078]], dtype=int64),\n  'precision': 0.9253071253071253,\n  'recall': 0.9253071253071253,\n  'f1_score': 0.9253071253071253},\n {'accuracy': 0.8968058968058968,\n  'classification_report': '              precision    recall  f1-score   support\\n\\n         0.0       0.96      0.92      0.94       875\\n         1.0       0.00      0.00      0.00        98\\n         2.0       0.86      0.96      0.91      1062\\n\\n    accuracy                           0.90      2035\\n   macro avg       0.60      0.63      0.61      2035\\nweighted avg       0.86      0.90      0.88      2035\\n',\n  'confusion_matrix': array([[ 803,    0,   72],\n         [   1,    0,   97],\n         [  36,    4, 1022]], dtype=int64),\n  'precision': 0.8968058968058968,\n  'recall': 0.8968058968058968,\n  'f1_score': 0.8968058968058968})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1 = evaluate_model(model_target1, y_test1, y_pred1)\n",
    "\n",
    "\n",
    "results2 = evaluate_model(model_target2, y_test2, y_pred2)\n",
    "results1,results2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train and evaluate LDA with outlier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X, y1, y2 = split_dataset(df_LDA_with_outlier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = split_train_test(X, y1)\n",
    "X_train2, X_test2, y_train2, y_test2 = split_train_test(X, y2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X_train_scaled1, X_test_scaled1 = standardize_features(X_train1, X_test1)\n",
    "X_train_scaled2, X_test_scaled2 = standardize_features(X_train2, X_test2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model_target1 = train_logistic_regression(X_train_scaled1, y_train1)\n",
    "model_target2 = train_logistic_regression(X_train_scaled2, y_train2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "y_pred1 = predict(model_target1, X_test_scaled1)\n",
    "y_pred2 = predict(model_target2, X_test_scaled2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.9366093366093367,\n 'classification_report': '              precision    recall  f1-score   support\\n\\n         0.0       0.97      0.93      0.95       875\\n         1.0       1.00      0.00      0.00        46\\n         2.0       0.91      0.98      0.94      1114\\n\\n    accuracy                           0.94      2035\\n   macro avg       0.96      0.64      0.63      2035\\nweighted avg       0.94      0.94      0.93      2035\\n',\n 'confusion_matrix': array([[ 818,    0,   57],\n        [   0,    0,   46],\n        [  26,    0, 1088]], dtype=int64),\n 'precision': 0.9366093366093367,\n 'recall': 0.9366093366093367,\n 'f1_score': 0.9366093366093367}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1 = evaluate_model(model_target1, y_test1, y_pred1)\n",
    "results1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.9085995085995086,\n 'classification_report': '              precision    recall  f1-score   support\\n\\n         0.0       0.97      0.93      0.95       875\\n         1.0       0.38      0.03      0.06        98\\n         2.0       0.87      0.97      0.92      1062\\n\\n    accuracy                           0.91      2035\\n   macro avg       0.74      0.64      0.64      2035\\nweighted avg       0.89      0.91      0.89      2035\\n',\n 'confusion_matrix': array([[ 815,    0,   60],\n        [   1,    3,   94],\n        [  26,    5, 1031]], dtype=int64),\n 'precision': 0.9085995085995086,\n 'recall': 0.9085995085995086,\n 'f1_score': 0.9085995085995086}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = evaluate_model(model_target2, y_test2, y_pred2)\n",
    "results2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train and evaluate PCA without outlier\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "X, y1, y2 = split_dataset(df_PCA_without_outlier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = split_train_test(X, y1)\n",
    "X_train2, X_test2, y_train2, y_test2 = split_train_test(X, y2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "X_train_scaled1, X_test_scaled1 = standardize_features(X_train1, X_test1)\n",
    "X_train_scaled2, X_test_scaled2 = standardize_features(X_train2, X_test2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model_target1 = train_logistic_regression(X_train_scaled1, y_train1)\n",
    "model_target2 = train_logistic_regression(X_train_scaled2, y_train2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "y_pred1 = predict(model_target1, X_test_scaled1)\n",
    "y_pred2 = predict(model_target2, X_test_scaled2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.9257985257985258,\n 'classification_report': '              precision    recall  f1-score   support\\n\\n         0.0       0.96      0.92      0.94       875\\n         1.0       1.00      0.00      0.00        46\\n         2.0       0.90      0.97      0.93      1114\\n\\n    accuracy                           0.93      2035\\n   macro avg       0.95      0.63      0.62      2035\\nweighted avg       0.93      0.93      0.92      2035\\n',\n 'confusion_matrix': array([[ 807,    0,   68],\n        [   0,    0,   46],\n        [  37,    0, 1077]], dtype=int64),\n 'precision': 0.9257985257985258,\n 'recall': 0.9257985257985258,\n 'f1_score': 0.9257985257985258}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluate_model(model_target1, y_test1, y_pred1)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train and evaluate LDA without outlier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "X, y1, y2 = split_dataset(df_LDA_without_outlier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = split_train_test(X, y1)\n",
    "X_train2, X_test2, y_train2, y_test2 = split_train_test(X, y2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X_train_scaled1, X_test_scaled1 = standardize_features(X_train1, X_test1)\n",
    "X_train_scaled2, X_test_scaled2 = standardize_features(X_train2, X_test2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "model_target1 = train_logistic_regression(X_train_scaled1, y_train1)\n",
    "model_target2 = train_logistic_regression(X_train_scaled2, y_train2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "y_pred1 = predict(model_target1, X_test_scaled1)\n",
    "y_pred2 = predict(model_target2, X_test_scaled2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.9331695331695332,\n 'classification_report': '              precision    recall  f1-score   support\\n\\n         0.0       0.97      0.93      0.95       875\\n         1.0       1.00      0.00      0.00        46\\n         2.0       0.91      0.98      0.94      1114\\n\\n    accuracy                           0.93      2035\\n   macro avg       0.96      0.63      0.63      2035\\nweighted avg       0.94      0.93      0.92      2035\\n',\n 'confusion_matrix': array([[ 812,    0,   63],\n        [   0,    0,   46],\n        [  27,    0, 1087]], dtype=int64),\n 'precision': 0.9331695331695332,\n 'recall': 0.9331695331695332,\n 'f1_score': 0.9331695331695332}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluate_model(model_target1, y_test1, y_pred1)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
